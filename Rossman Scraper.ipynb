{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import numpy as np\n",
    "\n",
    "def scrape_product_links():\n",
    "    products = []\n",
    "    try:\n",
    "        product_elements = driver.find_elements(By.XPATH, \"//a[starts-with(@href, '/Produkt')]\")\n",
    "        for product in product_elements:\n",
    "            product_link = product.get_attribute('href')\n",
    "            print(f'Found product: {product_link}')\n",
    "            products.append(product_link)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print(\"Could not find products on this page.\")\n",
    "    \n",
    "    return products\n",
    "\n",
    "def go_to_next_page():\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'a[data-testid=\"pagination-next-page\"]')\n",
    "        href_value = next_button.get_attribute('href')\n",
    "        driver.get(str(href_value))\n",
    "\n",
    "        print(\"Going to the next page.\")\n",
    "\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        print(\"No more pages left.\")\n",
    "        return False\n",
    "\n",
    "# Set up Edge options for headless mode\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(\"--headless\")\n",
    "edge_options.add_argument(\"--disable-gpu\")  # Recommended for headless mode\n",
    "edge_options.add_argument(\"--no-sandbox\")   # Optional for headless mode\n",
    "\n",
    "# Initialize the Edge WebDriver with headless options\n",
    "driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=edge_options)\n",
    "\n",
    "# Main scraping loop\n",
    "all_products = []\n",
    "\n",
    "# URL of the search result page\n",
    "url = 'https://www.rossmann.pl/szukaj?CategoryId=13049&Search=krem%20do%20twarzy'\n",
    "driver.get(url)\n",
    "\n",
    "while True:\n",
    "    all_products.extend(scrape_product_links())\n",
    "    \n",
    "    # Wait for a few seconds before moving to the next page\n",
    "    driver.implicitly_wait(0.5)\n",
    "    \n",
    "    # Try to go to the next page, if it fails, break the loop\n",
    "    if not go_to_next_page():\n",
    "        break\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "with open(\"links.txt\", 'w') as outfile:\n",
    "    outfile.writelines((str(product)+'\\n' for product in np.unique(all_products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up Edge options for headless mode\n",
    "edge_options = Options()\n",
    "edge_options.add_argument(\"--headless\")\n",
    "edge_options.add_argument(\"--disable-gpu\")  # Recommended for headless mode\n",
    "edge_options.add_argument(\"--no-sandbox\")   # Optional for headless mode\n",
    "\n",
    "# Initialize the Edge WebDriver with headless options\n",
    "driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=edge_options)\n",
    "\n",
    "# Path to the file containing product links\n",
    "product_links_file_path = 'links.txt'\n",
    "\n",
    "# Read all links into a list\n",
    "with open(product_links_file_path, 'r') as file:\n",
    "    links = [line.strip() for line in file if line.strip()]  # Read and clean up links\n",
    "\n",
    "total_links = len(links)\n",
    "print(f\"Total links to process: {total_links}\")\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    # Process each link\n",
    "    for index, link in enumerate(links, start=1):\n",
    "        print(f\"Processing link {index} of {total_links}: {link}\")\n",
    "        if index > 100:\n",
    "            break\n",
    "\n",
    "        driver.get(link)\n",
    "\n",
    "        try:\n",
    "            # Locate the button with the text \"Składniki\"\n",
    "            button = driver.find_element(By.XPATH, '//button[span[text()=\"Składniki\"]]')\n",
    "            # Find the parent container of the button and locate the <p> element\n",
    "            parent_div = button.find_element(By.XPATH, '..//..')  # Adjust XPath if needed to navigate to the parent container\n",
    "            p_element = parent_div.find_element(By.CSS_SELECTOR, 'p.styles-module_productDescriptionContent--76j9I')\n",
    "            ingredients_text = p_element.get_attribute('innerHTML')\n",
    "\n",
    "            soup = BeautifulSoup(ingredients_text, 'html.parser')\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "            cleaned_text = cleaned_text.strip()\n",
    "\n",
    "            data.append({'Product_url': link, 'Ingredients': ingredients_text})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing link {link}\")\n",
    "            data.append({'Product_url': link, 'Ingredients': 'Error retrieving ingredients'})\n",
    "\n",
    "        driver.implicitly_wait(0.2)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"ingredients.tsv\", sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ingredients_df = pd.read_csv(\"cleaned_ingredients.csv\", sep=\";\")\n",
    "\n",
    "\n",
    "split_elements = ingredients_df['Ingredients'].str.split(r'[,.•*]')\n",
    "\n",
    "# Step 2: Flatten the list of lists\n",
    "flattened_elements = [item.strip() for sublist in split_elements for item in sublist]\n",
    "\n",
    "# Step 3: Convert the list to a set to remove duplicates\n",
    "unique_elements = set(flattened_elements)\n",
    "\n",
    "# Step 4: Create a new DataFrame from the unique elements\n",
    "unique_df = pd.DataFrame(list(unique_elements), columns=['unique_elements'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unique_df.to_csv(\"unique_ingredients\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 1: Load the data\n",
    "ingredients_df = pd.read_csv(\"cleaned_ingredients.csv\", sep=\";\")\n",
    "\n",
    "# Step 2: Define the dictionary for replacements\n",
    "replace_dict = {\n",
    "    \"WATER\": [\"AQUA/WATER\", \"AQUA\", \"AQUA (WATER)\", \"WATER / WATER\", \"WATER (WATER)\"]\n",
    "    # Add more replacements here as needed\n",
    "}\n",
    "\n",
    "# Step 3: Apply transformations to the 'Ingredients' column\n",
    "ingredients_df['Ingredients'] = ingredients_df['Ingredients'].str.upper()  # Convert to uppercase\n",
    "ingredients_df['Ingredients'] = ingredients_df['Ingredients'].str.replace(r'\\*', '', regex=True)  # Remove \"*\"\n",
    "\n",
    "# Step 4: Apply replacements based on the replace_dict\n",
    "# Flatten the dictionary into a single mapping\n",
    "flat_replace_dict = {re.escape(pattern): replacement for replacement, patterns in replace_dict.items() for pattern in patterns}\n",
    "\n",
    "# Perform replacements\n",
    "ingredients_df['Ingredients'] = ingredients_df['Ingredients'].replace(flat_replace_dict, regex=True)\n",
    "\n",
    "# Step 5: Split the 'Ingredients' column by multiple delimiters\n",
    "split_elements = ingredients_df['Ingredients'].str.split(r'[,.•*]+', expand=False)\n",
    "\n",
    "# Step 6: Flatten the list of lists and clean up whitespace\n",
    "flattened_elements = [item.strip() for sublist in split_elements for item in sublist if item.strip()]\n",
    "\n",
    "# Step 7: Count occurrences of each unique ingredient\n",
    "ingredient_counts = pd.Series(flattened_elements).value_counts()\n",
    "\n",
    "# Step 8: Create a DataFrame from the unique ingredients and their counts\n",
    "unique_df = pd.DataFrame({\n",
    "    'unique_elements': ingredient_counts.index,\n",
    "    'count': ingredient_counts.values\n",
    "})\n",
    "\n",
    "# Step 9: Save the unique ingredients and their counts to a CSV file\n",
    "unique_df.to_csv(\"unique_ingredients.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
